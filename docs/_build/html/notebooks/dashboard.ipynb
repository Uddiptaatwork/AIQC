{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AIQC makes comparing and evaluating models effortless with its reactive [Dash-Plotly](https://aiqc.medium.com/dash-is-deeper-than-dashboards-5ab7414f121e) user interface. The following dashboards put precalculated metrics & charts for each split/fold of every model right at your fingertips. \n",
    "\n",
    "> Reference the [Evaluation](evaluation.html) section for more information about the plots and metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Experiment Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![tracker](../_static/images/dashboard/experiment_tracker.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, practitioners continually improve their algorithm by experimenting with different combinations of architectures and parameters. This iterative process generates a lot of post-processing data, and it's difficult to figure out which model is the best just by staring at hundreds of rows of raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models Head-to-Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![head2head](../_static/images/dashboard/compare_models.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head-to-head comparison provides a deep dive that helps tease out the answers to challenging questions:\n",
    "\n",
    "> How does a practitioner know that 'model A' is actually better than 'model B' for their use case? Is one model slightly more biased than the other? What characteristics in the data is each model relying on? Can we get higher performance if we train for just a bit longer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What-If Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sensitivity](../_static/images/dashboard/what_if.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ever wonder \"What if?\" By providing a dynamic user inferface for inference, AIQC allows you to tweak the inputs for a scenario in order to simulate its outcome.\n",
    "\n",
    "Its applications are endless: Will the patient *survive* if their blood pressure drops? Will this drug be *effective* with 1 more rotational bond? Will the gene editing *increase* CO2 sequestration?\n",
    "\n",
    "\n",
    "- By default, the feature inputs are populated with either the median numeric/ mode categoric value depending on their dtype. Metadata about the feature's distribution can be seen by hovering over the column name.\n",
    "- If feature importance was enabled during model evaluation, then the feature columns are presented in rank-order of median feature importance (as seen in the first row of the hover tooltip).\n",
    "- The inputs are pre/post-processed via [aiqc.mlops.Inference](api_high_level.ipynb#3.-Inference) using the original model's [aiqc.mlops.Pipeline](api_high_level.ipynb#1.-Pipeline).\n",
    "- Clicking the star uses `BaseModel.flip_star()` to toggle `Prediction.is_starred` as a favorite indicator.\n",
    "- Right now this page is only configured for supervised analysis (regression, binary classification, multi-label classification) on tabular data. However, this foundation can easily be extended to support the other AIQC data/analysis combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The app must be launched from the command line as a Python module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "$ python -m aiqc.ui.app       \n",
    "\n",
    "Dash is running on http://127.0.0.1:9991/\n",
    "\n",
    " * Running on http://127.0.0.1:9991 (Press CTRL+C to quit)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "If you attempt to terminate the server with `CTRL+Z` by accident, then the port will get hung. The [freeport](https://pypi.org/project/freeport/) package makes it easy to release the port in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The `--port int` and `--debug` mode are configurable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "```\n",
    "$ python -m aiqc.ui.app --help\n",
    "\n",
    "    usage: aiqc.ui.app [-h] [--port] [--debug] [--no-debug]\n",
    "\n",
    "    Launch AIQC's Dash-Plotly UI for experiment tracking\n",
    "    https://dash.plotly.com/devtools\n",
    "\n",
    "    optional arguments:\n",
    "      -h, --help  show this help message and exit\n",
    "      --port      localhost:<port> to run on. Default=9991\n",
    "      --debug     Raises errors and inspects callbacks.\n",
    "      --no-debug  By default, neither raises errors nor inspects callbacks.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The page refreshes every 10 seconds.\n",
    "\n",
    "> If, for some reason, you find that your queries are taking longer than 10 seconds to finish, please start a discussion: https://github.com/aiqc/AIQC/discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about JupyterDash?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, the UI was built around `jupyter_dash`, which enabled running the Dash app within either a JupyterLab cell or tab. However, this approach was not stable for the following reasons:\n",
    "\n",
    "- [Hung & unkillable ports](https://github.com/plotly/jupyter-dash/issues/33)\n",
    "  - When `_terminate_server_for_port` was removed in v0.4.2, it became unusable.\n",
    "- [Werkzeug deprecation warnings](https://github.com/plotly/jupyter-dash/issues/63)\n",
    "\n",
    "JupyterLab ships with a terminal. So technically the app can still be launched from within the JupyterLab user interface without resorting to Pythonic `sys` commands."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
